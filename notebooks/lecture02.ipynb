{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccac270d",
   "metadata": {},
   "source": [
    "Virtual Acoustics and Immersive Audio Workshop - CCRMA Stanford University  \n",
    "22.07.25 - Orchisama Das, Gloria Dal Santo\n",
    "  \n",
    "### L02: Artificial Reverberation \n",
    "\n",
    "In this assignment we will \n",
    "- Load a response measured in a shoebox room with known dimensions, source-receiver positions\n",
    "- Deconvolve the sine sweep from the recorded response to extract the RIR \n",
    "- Plot the EDC, NED, and compute the broadband T60\n",
    "- Synthesize the RIR with the ISM in pyroomacoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb18842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pyroomacoustics as pra\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import (\n",
    "    audioread,\n",
    "    find_onset)\n",
    "from room_acoustics.analysis import (\n",
    "    compute_edc, \n",
    "    estimate_rt60,\n",
    "    normalized_echo_density)\n",
    "from room_acoustics.plot import (\n",
    "    plot_time_domain,\n",
    "    plot_spectrogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1dc7c3",
   "metadata": {},
   "source": [
    "#### 1. Load Response and Deconvolve the RIR\n",
    "\n",
    "We'll be using `11_Speaker_IGL_ch1.wav` and `DrySweep.wav`.  \n",
    "- 1.1 Load the signals and their sampling frequency using the `audioread` function. \n",
    "- 1.2 Plot their time domain response, their spectrogram, and play them. Use `plot_time_domain` and `plot_spectrogram` from \n",
    "- 1.3 Deconvolve the signal to extract the RIR and plot it. Use the numpy's `convolve` function (The recording is fairly long! Expect it to run for a minute or so). Be careful of which `mode` to use.  \n",
    "\n",
    "Note: the sine sweep has training and leading silence. The important information is contained between the 1st and 11th second.\n",
    "You can also try to code the sine sweep yourself using the formula given in the assignment sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57220538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Play Recording ---\n",
    "rec_path = Path('..') / 'data' / '11_Speaker_IGL_ch1.wav'\n",
    "rec, fs = audioread(str(rec_path))\n",
    "plot_time_domain(rec, fs, 'Recorded Response')\n",
    "plot_spectrogram(rec, fs, 'Recorded Response')\n",
    "ipd.display(ipd.Audio(rec, rate=fs))\n",
    "\n",
    "\n",
    "# --- Load and Play Sine Sweep ---\n",
    "sweep_path = Path('..') / 'data' / 'DrySweep.wav'\n",
    "sweep, fs = audioread(str(sweep_path))\n",
    "# trim the sweep so that it contains only the non zero part\n",
    "sweep = sweep[48000:48000 + 10*fs]\n",
    "plot_time_domain(sweep, fs, 'Sine Sweep')\n",
    "plot_spectrogram(sweep, fs, 'Sine Sweep')\n",
    "ipd.display(ipd.Audio(sweep, rate=fs))\n",
    "\n",
    "\n",
    "# --- Deconvolve the Recording with the Sine Sweep to Extract RIR ---\n",
    "\n",
    "#### WRITE YOUR CODE ####\n",
    "# Create an inverse sweep by flipping the sweep signal\n",
    "# Deconvolve the recording with the inverse sweep to extract the RIR\n",
    "# Normalize the RIR to have maximum absolute value of 1\n",
    "# Find and remove the silence before the onset of the RIR (you can use the `find_onset` function)\n",
    "# plot time response and spectrogram \n",
    "\n",
    "ipd.display(ipd.Audio(rir, rate=fs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef01ac0",
   "metadata": {},
   "source": [
    "#### 2. Extract the Acoustic Parameters\n",
    "\n",
    "For the obtained RIR\n",
    "- 2.1 Compute and plot the EDC, T60, and NED using the functions implemented during Assignment 1\n",
    "\n",
    "Note: compute the NED only for the first 4 seconds as it gets very noisy after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute the EDC, estimate the T60 and compute the NED (Ref: Lecture 1) ---\n",
    "\n",
    "#### WRITE YOUR CODE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e417851",
   "metadata": {},
   "source": [
    "#### 3. ISM synthesis of the RIR \n",
    "\n",
    "Use `pyroomacoustics` to synthesize the RIR given the room dimensions, the absorption and scattering properties of the surfaces, and source-receiver positions.\n",
    "- 3.1 Instantiate the Shoebox class from pyroomacoustics. References: https://github.com/LCAV/pyroomacoustics/blob/f4144d216fd8776a91f40b600ee1a30bbcd228da/pyroomacoustics/room.py#L2987 and https://github.com/LCAV/pyroomacoustics/blob/master/examples/room_shoebox_3d_rt.py (the latter shows you an example on how to use it)\n",
    "- 3.2 Run the usual acoustic parameters analysis and compare them to those of the original RIR \n",
    "- 3.3 Try different configurations (different orders of image sources, with and without ray tracing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09732d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ISM synthesis of the RIR ---\n",
    "room_dims = [6.1, 12.2, 6.1]  # Dimensions of the racquetball court (m)\n",
    "source_pos = [5.3, 6.7, 1.52]  # Position of the source (m)\n",
    "mic_pos = [1, 10.5, 1.52]  # Position of the microphone (m)\n",
    "\n",
    "floor_abs = {\n",
    "    'description': 'Wooden Floor',\n",
    "    'coeffs': [0.150, 0.150, 0.110, 0.100, 0.070, 0.060, 0.070, 0.070],\n",
    "    'center_freqs': [63, 125, 250, 500, 1000, 2000, 4000, 8000],\n",
    "}\n",
    "wall_abs = {\n",
    "    'description': 'Wooden Walls',\n",
    "    'coeffs': [0.042, 0.037, 0.039, 0.012, 0.004, 0.003, 0.014, 0.04],\n",
    "    'center_freqs': [63, 125, 250, 500, 1000, 2000, 4000, 8000],\n",
    "}\n",
    "scattering = {\n",
    "    \"description\": \"Random diffuser\", \n",
    "    \"coeffs\": [0.01, 0.01, 0.08, 0.08, 0.05, 0.08, 0.1, 0.1],\n",
    "    \"center_freqs\": [63, 125, 250, 500, 1000, 2000, 4000, 8000],\n",
    "}\n",
    "\n",
    "materials = pra.make_materials(\n",
    "    ceiling=(wall_abs, scattering),\n",
    "    floor=(floor_abs, scattering),\n",
    "    east=(wall_abs, scattering),\n",
    "    west=(wall_abs, scattering),\n",
    "    north=(wall_abs, scattering),\n",
    "    south=(wall_abs, scattering),\n",
    ")\n",
    "\n",
    "shoebox = (\n",
    "#### WRITE YOUR CODE ####\n",
    "# use the `pra.ShoeBox` to create a room with the given dimensions, materials, and parameters\n",
    "# You can try with max_order = 20 amd with/without ray tracing\n",
    ")\n",
    "\n",
    "# run the synthesis\n",
    "shoebox.image_source_model()\n",
    "shoebox.ray_tracing()\n",
    "shoebox.compute_rir()\n",
    "rir_ism = shoebox.rir[0][0].copy()\n",
    "plot_time_domain(rir_ism, fs, title=f'RIR from ISM')\n",
    "plot_spectrogram(rir_ism, fs, title='RIR from ISM', clim=[-200, None])\n",
    "rt60_sabine = shoebox.rt60_theory(formula=\"sabine\")\n",
    "ipd.display(ipd.Audio(rir_ism, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a65b8c",
   "metadata": {},
   "source": [
    "#### 4. Convolve\n",
    "\n",
    "Convolve the extracted and generated RIRs with the dry signals `data/Drums.wav`, `data/Sax.wav`, and `data/Speech.wav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convolve Anechoic Sounds with RIRs ---\n",
    "anechoic = ['Drums', 'Sax', 'Speech']\n",
    "\n",
    "for filename in anechoic:\n",
    "    rec_path = Path('..') / 'data' / f'{filename}.wav'\n",
    "    rec, fs = audioread(str(rec_path))\n",
    "    \n",
    "    # Convolve the recording with the RIR\n",
    "    #### WRITE YOUR CODE ####\n",
    "    # it's good practice to normalize the convolved signal\n",
    "    print(f\"Convolved {filename} with RIR from recorded RIR\")\n",
    "    ipd.display(ipd.Audio(convolved, rate=fs))\n",
    "\n",
    "for filename in anechoic:\n",
    "    rec_path = Path('..') / 'data' / f'{filename}.wav'\n",
    "    rec, fs = audioread(str(rec_path))\n",
    "    \n",
    "    # Convolve the recording with the RIR\n",
    "    #### WRITE YOUR CODE ####\n",
    "    # it's good practice to normalize the convolved signal\n",
    "    print(f\"Convolved {filename} with RIR from ISM\")\n",
    "    ipd.display(ipd.Audio(convolved, rate=fs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
